---
title: "Using optimall"
author: "Jasper Yang"
date: "Last updated: `r format(Sys.Date(), '%B %d, %Y')`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{optimall-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

library(optimall)
library(DiagrammeR)

phase1 <- read.csv("/Volumes/ShawLab/PCORI Healthy Weight/JasperWork/Phase1SIM.csv")
```


## Introduction

When a study population is composed of heterogeneous subpopulations, stratified random sampling techniques are often employed to obtain more precise estimates of population characteristics. Efficiently allocating samples to strata under this method is a crucial step in the study design, especially when sampling is expensive. 

`optimall` offers a collection of functions that are designed to streamline the process of optimum sample allocation, specifically under an adaptive, multi-phase approach. Its main functions allow users to:

* Split existing strata into smaller strata based on values or percentiles of other variables.

* Calculate the optimum number of samples to allocate to each stratum in a given study in order to minimize the variance of an estimate of interest. 

* Optimally allocate a fixed number of samples to an ancillary sampling wave based on results from a prior wave. 

When used together, these functions can automate most of the sampling workflow. This vignette will introduce the theoretical framework behind the functions before demonstrating how they can be used to work with sampling data in R.

## Optimal Allocation
Assuming that the per-unit sampling cost is the same in each stratum and that $S_h$, the standard deviation of the variable of interest within each stratum, can be estimated, Neyman (1934) presented the following solution to optimally allocate $n$ samples among $H$ strata:  

$$n_h = n \frac{N_hS_h}{\sum_{i=1}^H N_iS_i}$$
This formula, known as Neyman allocation, is widely used as a robust method for minimizing the variance of an estimate. It can be called in `optimall`. Neyman allocation offers the advantage of outputting sampling fractions that can later be multiplied by $n$ or taken on their own if $n$ is not known.  

While Neyman allocation has a strong theoretical backing, Wright (2014) points out some limitations that make it sub-optimal in practice. 

1. Neyman does not require that the solution to $n_h$ is an integer, and thus it rarely is. When taking a fraction of a sample is not practical, researchers are forced to stray from the theory by rounding the sample sizes in ways that are not always optimal. 
2. Closely related to the first issue, the rounded results for $n_h$ are not guarunteed to sum to $n$. This is clearly sub-optimal.

Wright offers revised algorithms that solve these issues which can also be implemented in `optimall`. Essentially, his approaches use linear constraints to optimize the allocation of samples over a space of integer values. He makes use of within-stratum variance and population stratum size to generate priority values, which in turn dictate how many samples should be taken from each stratum. To learn more about the specifics of these algorithms, see Wright (2014).

`optimall` allows users to select between Neyman allocation, Wright Algorithm I, and Wright Algorithm II in the `method` argument of the `optimum_allocation` function. `optimum_allocation` defaults to using Wright Algorithm II because it is the only method of the three that requires an unbiased estimate of the variance and always produces the global optimum allocation. This algorithm requires that at least 2 samples are taken from each stratum.  In `optimall`, stratum sampling sizes for both Wright algorithms are also constrained from above at $N_h$, the population stratum size, using the methods for constraints that Wright details in Algorithm III. 

## Adaptive, Multi-Wave Sampling
When measuring variables of interest is expensive or difficult, it is often favorable to employ an adaptive, multi-wave sampling design. This approach, which is well-documented in McIsaac and Cook (2014), involves multiple phases of sampling where information from prior waves is used to inform the optimum sampling design of subsequent ones. With the understanding that both Neyman and Wright's optimum allocation methods depend heavily on standard deviation estimates for the variable of interest, the benefit of multi-wave sampling is clear to see. Sample allocations based on prior waves will use better estimates of the variable of interest compared to a single wave, and they will therefore be more optimal. 

In the design described by McIsaac and Cook, a large phase-I sample is first taken to measure the inexpensive covariates and/or outcome. The results of this phase will define strata which are then sampled non-optimally (through proportional or balanced sampling) for measurement of the expensive variable in phase-IIa. The phase-IIa results are used to estimate the standard deviation required to optimally allocate the next wave of samples. This process is iterated until the desired sample size for the variable of interest is achieved. Below is an outline of the workflow, which is facilitated by `optimall`:
<br />
<br />

<center>

```{r, fig.align='center', echo=FALSE}
DiagrammeR::grViz("digraph {
  graph [layout = dot, rankdir = TB]
  
  node [shape = rectangle, fixedsize = true, width = 8.5, height = 1.2, fontname = Helvetica, fontsize  = 20]   
  rec1 [label = <<b>Phase-I:</b><br/>A large sample of inexpensive variables, <br/> define strata based on results.>]
  rec2 [label = <<b>Phase-IIa:</b><br/>Initial stratified sample of expensive variable taken without <br/>optimum allocation>]
  rec3 [label = <<b>Phase-IIb:</b><br/>Second sample of expensive variable with optimum allocation <br/> based on Phase-IIa results>]
  rec4 [label = <<b>Phase-IIc - Phase-IIfinal:</b><br/>Combine previous waves of Phase-II together and repeat <br/> sampling with re-calculated optimum allocation until desired total <br/> sample size for expensive variable is reached at Phase-IIfinal>]
  
  # edge definitions with the node IDs
  rec1 -> rec2 -> rec3 -> rec4

  }", 
  height = 250, width = 700)
```

</center>

<br />

`optimall` allows users to input phase-I data and iteratively allocate samples for subsequent waves with the function `allocate_wave`. Along the way, the user may also want to split or join imbalanced strata. `optimall` makes this easy with the `split_strata` function.

## Example Workflow: Using `optimall` to Work with Healthy Weight Data

#### *Overview*
This example uses a simulated dataset to demonstrate how `optimall` can be used in an adaptive, multi-wave sampling workflow. The dataset is based on a real study analyzing the association between maternal weight gain during pregancy and the risk of childhood obesity after controlling for a number of clinical and demographic covariates. 

The data is obtained from electronic health records, which are known to be error-prone. In a perfect world, we would validate every observation in our sample, but auditing electronic health records is an expensive and difficult task. We determine that we can only reasonably afford to validate 750 out of the 10,335 child-mother pairs. To get the most out of these 750 samples, we want to minimize the variance of our corrected estimates. This goal will be best accomplished through an adaptive, multi-wave sampling design.

#### *Phase-I*
Data for 10,335 mother-child pairs was collected during Phase-I and read into R as a dataframe. Each row represents a unique mother-child pair, and columns include ID number, a binary indicator for the outcome variable child obesity, and an estimate of the mother's weight change during pregnancy among other variables of interest. 

```{r}
dim(phase1)
names(phase1)
head(phase1)
```

In this case,  . 
We decide to split our population into 6 non-overlapping strata. Each stratum is defined by a unique combination of childhood obesity outcome (0/1) and global percentile of maternal weight gain (â‰¤25th, 25th - 75th, >75th). We can accomplish this quickly in `optimall` using the `split_strata` function. 

```{r}
phase1 <- split_strata(data = phase1, strata = "diab", split = NULL, split_var = "mother_weight_change_est", type = "global quantile", split_at = c(0.25,0.75))
```
We now have the same `phase1` data with a new column specifying the strata we have defined. Since we used `"diab"` as the `strata` argument, optimall has changed its name to `"old_strata"`, but we can change it back if we would like. 

```{r}
dim(phase1)
table(phase1$new_strata)
names(phase1)[names(phase1) == "old_strata"] <- "diab"
```

In subsequent waves, we plan to target audits to records that are more infuential.  

#### *Phase-IIa*

#### *Phase-IIb*

#### *

* Introduce the given, error prone, data. We call this the "phase I" data according to the the notation from McIsaac.

* Show how the strata are created and, briefly, why

* We have 250 samples for wave 1, let's optimally allocate them in order to minimize y.

* Gather samples, allocate_wave for next 250.

* Look at results, decide to one split strata further, then re-allocate wave. 


## References
